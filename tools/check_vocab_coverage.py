#!/usr/bin/env python3
"""
è¯æ±‡è¦†ç›–æ£€æŸ¥å·¥å…·
æ£€æŸ¥å°è¯´å†…å®¹æ˜¯å¦è¦†ç›–äº†æ‰€æœ‰æ ¸å¿ƒè¯æ±‡
"""

import re
import os
import sys
import json
import argparse

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
RAW_STORY_FILE = os.path.join(BASE_DIR, "raw_story.txt")
PROMPT_FILE = os.path.join(BASE_DIR, "current_prompt.txt")
PROJECT_ROOT = os.path.dirname(BASE_DIR)
GENERATED_DIR = os.path.join(PROJECT_ROOT, "src", "data", "generated")


def extract_target_words_from_prompt() -> list:
    """ä» prompt æ–‡ä»¶ä¸­æå–æ ¸å¿ƒè¯æ±‡åˆ—è¡¨"""
    if not os.path.exists(PROMPT_FILE):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° {PROMPT_FILE}")
        return []
    
    with open(PROMPT_FILE, "r", encoding="utf-8") as f:
        content = f.read()
    
    # æŸ¥æ‰¾æ ¸å¿ƒè¯æ±‡éƒ¨åˆ†
    if "## æ ¸å¿ƒè¯æ±‡ï¼ˆå¿…é¡»å…¨éƒ¨ä½¿ç”¨ï¼‰" not in content:
        print("âŒ é”™è¯¯ï¼šåœ¨ prompt æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°æ ¸å¿ƒè¯æ±‡éƒ¨åˆ†")
        return []
    
    # æå–æ ¸å¿ƒè¯æ±‡éƒ¨åˆ†
    vocab_section = content.split("## æ ¸å¿ƒè¯æ±‡ï¼ˆå¿…é¡»å…¨éƒ¨ä½¿ç”¨ï¼‰")[1]
    if "## è¾“å‡ºè¦æ±‚" in vocab_section:
        vocab_section = vocab_section.split("## è¾“å‡ºè¦æ±‚")[0]
    elif "## å¤ä¹ è¯æ±‡" in vocab_section:
        vocab_section = vocab_section.split("## å¤ä¹ è¯æ±‡")[0]
    
    # æå–æ‰€æœ‰å•è¯ï¼ˆ- word æ ¼å¼ï¼‰
    words = re.findall(r'-\s*(\w+)', vocab_section)
    target_words = [w.strip().lower() for w in words if w.strip()]
    
    return target_words


def extract_used_words_from_story(story_content: str) -> set:
    """ä»å°è¯´å†…å®¹ä¸­æå–æ‰€æœ‰ä½¿ç”¨çš„å•è¯ï¼ˆ{word|meaning} æ ¼å¼ï¼‰"""
    pattern = r'\{([^|]+)\|'
    matches = re.findall(pattern, story_content)
    used_words = set([m.strip().lower() for m in matches if m.strip()])
    return used_words


def load_story_from_generated(book_id: str) -> str:
    """
    ä» src/data/generated/book-xxxx.json è¯»å–ç« èŠ‚å†…å®¹
    """
    filename = f"{book_id}.json" if book_id.endswith(".json") is False else book_id
    path = os.path.join(GENERATED_DIR, filename)
    if not os.path.exists(path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç« èŠ‚æ–‡ä»¶ï¼š{path}")
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, dict) or "content" not in data:
        raise ValueError(f"ç« èŠ‚æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼ˆç¼ºå°‘ contentï¼‰ï¼š{path}")
    content = data.get("content", "")
    if not isinstance(content, str):
        raise ValueError(f"ç« èŠ‚æ–‡ä»¶ content å­—æ®µä¸æ˜¯å­—ç¬¦ä¸²ï¼š{path}")
    return content


def find_latest_generated_book_file() -> str:
    """
    æ‰¾åˆ° src/data/generated ä¸‹æœ€æ–°çš„ book-*.json
    è¿”å›æ–‡ä»¶åï¼ˆä¾‹å¦‚ book-20260112165132.jsonï¼‰
    """
    if not os.path.isdir(GENERATED_DIR):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›®å½•ï¼š{GENERATED_DIR}")
    candidates = []
    for name in os.listdir(GENERATED_DIR):
        if name.startswith("book-") and name.endswith(".json"):
            path = os.path.join(GENERATED_DIR, name)
            try:
                mtime = os.path.getmtime(path)
            except OSError:
                continue
            candidates.append((mtime, name))
    if not candidates:
        raise FileNotFoundError(f"{GENERATED_DIR} ä¸‹æ²¡æœ‰æ‰¾åˆ° book-*.json ç« èŠ‚æ–‡ä»¶")
    candidates.sort(key=lambda x: x[0], reverse=True)
    return candidates[0][1]


def main():
    print("=" * 60)
    print("ğŸ“Š è¯æ±‡è¦†ç›–æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    print()

    parser = argparse.ArgumentParser(description="æ£€æŸ¥å°è¯´å†…å®¹æ˜¯å¦è¦†ç›– current_prompt.txt ä¸­çš„æ ¸å¿ƒè¯æ±‡")
    parser.add_argument("--book-id", type=str, default="", help="ä¹¦ç±IDï¼Œä¾‹å¦‚ book-20260112165132ï¼ˆå¯¹åº” src/data/generated/book-*.jsonï¼‰")
    parser.add_argument("--latest", action="store_true", help="æ£€æŸ¥æœ€æ–°ç”Ÿæˆ/ä¸Šæ¶çš„é‚£æœ¬ä¹¦ï¼ˆæŒ‰ src/data/generated/book-*.json ä¿®æ”¹æ—¶é—´ï¼‰")
    parser.add_argument("--raw", action="store_true", help="å¼ºåˆ¶ä» tools/raw_story.txt è¯»å–ï¼ˆä¸­è½¬æ–‡ä»¶ï¼‰")
    args = parser.parse_args()
    
    # 1. æå–æ ¸å¿ƒè¯æ±‡
    print("ğŸ“‹ æå–æ ¸å¿ƒè¯æ±‡åˆ—è¡¨...")
    target_words = extract_target_words_from_prompt()
    
    if not target_words:
        print("âŒ æ— æ³•æå–æ ¸å¿ƒè¯æ±‡ï¼Œè¯·æ£€æŸ¥ current_prompt.txt")
        sys.exit(1)
    
    print(f"âœ… æ‰¾åˆ° {len(target_words)} ä¸ªæ ¸å¿ƒè¯æ±‡")
    print(f"   ç¤ºä¾‹ï¼š{', '.join(target_words[:10])}...")
    
    # 2. è¯»å–å°è¯´å†…å®¹ï¼ˆä¼˜å…ˆä»å·²ä¸Šæ¶çš„ generated ç« èŠ‚æ–‡ä»¶è¯»å–ï¼‰
    print(f"\nğŸ“– è¯»å–å°è¯´å†…å®¹...")
    story_content = ""
    source_hint = ""
    try:
        if args.raw:
            source_hint = RAW_STORY_FILE
            if not os.path.exists(RAW_STORY_FILE):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ° {RAW_STORY_FILE}")
            with open(RAW_STORY_FILE, "r", encoding="utf-8") as f:
                story_content = f.read().strip()
        elif args.book_id:
            source_hint = f"{args.book_id}.json"
            story_content = load_story_from_generated(args.book_id).strip()
        elif args.latest:
            latest = find_latest_generated_book_file()
            source_hint = latest
            story_content = load_story_from_generated(latest).strip()
        else:
            # é»˜è®¤ï¼šå¦‚æœ raw_story.txt æœ‰å†…å®¹å°±ç”¨ rawï¼›å¦åˆ™ç”¨ latest
            if os.path.exists(RAW_STORY_FILE):
                with open(RAW_STORY_FILE, "r", encoding="utf-8") as f:
                    tmp = f.read().strip()
                if tmp:
                    source_hint = RAW_STORY_FILE
                    story_content = tmp
            if not story_content:
                latest = find_latest_generated_book_file()
                source_hint = latest
                story_content = load_story_from_generated(latest).strip()
    except Exception as e:
        print(f"âŒ è¯»å–å°è¯´å†…å®¹å¤±è´¥ï¼š{e}")
        print("ğŸ’¡ ä½ å¯ä»¥ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼è¿è¡Œï¼š")
        print("   - æ£€æŸ¥æœ€æ–°ä¸Šæ¶ï¼špython3 check_vocab_coverage.py --latest")
        print("   - æŒ‡å®šä¹¦ç±IDï¼špython3 check_vocab_coverage.py --book-id book-20260112165132")
        print("   - å¼ºåˆ¶ç”¨ raw_storyï¼špython3 check_vocab_coverage.py --raw")
        sys.exit(1)

    if not story_content:
        print("âŒ å°è¯´å†…å®¹ä¸ºç©ºï¼Œæ— æ³•æ£€æŸ¥è¦†ç›–ç‡ã€‚")
        print(f"   å½“å‰æ¥æºï¼š{source_hint or 'æœªçŸ¥'}")
        sys.exit(1)
    
    print(f"âœ… å°è¯´å†…å®¹é•¿åº¦ï¼š{len(story_content)} å­—ç¬¦")
    if source_hint:
        print(f"   æ¥æºï¼š{source_hint}")
    
    # 3. æå–ä½¿ç”¨çš„å•è¯
    print(f"\nğŸ” æå–å°è¯´ä¸­ä½¿ç”¨çš„å•è¯...")
    used_words = extract_used_words_from_story(story_content)
    print(f"âœ… æ‰¾åˆ° {len(used_words)} ä¸ªæ ‡è®°çš„å•è¯")
    if used_words:
        print(f"   ç¤ºä¾‹ï¼š{', '.join(list(used_words)[:10])}...")
    
    # 4. æ£€æŸ¥è¦†ç›–æƒ…å†µ
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è¯æ±‡è¦†ç›–æ£€æŸ¥ç»“æœ")
    print(f"{'='*60}")
    
    missing_words = []
    for word in target_words:
        if word.lower() not in used_words:
            missing_words.append(word)
    
    used_count = len(target_words) - len(missing_words)
    coverage_percent = (used_count / len(target_words) * 100) if target_words else 0
    
    print(f"ğŸ“‹ æ ¸å¿ƒè¯æ±‡æ€»æ•°ï¼š{len(target_words)} ä¸ª")
    print(f"âœ… å·²ä½¿ç”¨ï¼š{used_count} ä¸ª ({coverage_percent:.1f}%)")
    print(f"âŒ ç¼ºå¤±ï¼š{len(missing_words)} ä¸ª")
    
    if missing_words:
        print(f"\nâš ï¸  ç¼ºå¤±çš„å•è¯åˆ—è¡¨ï¼š")
        for i, word in enumerate(missing_words, 1):
            print(f"   {i:2d}. {word}")
        print(f"\nğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥å°è¯´å†…å®¹ï¼Œç¡®ä¿æ‰€æœ‰æ ¸å¿ƒè¯æ±‡éƒ½å·²ä½¿ç”¨")
    else:
        print(f"\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰ {len(target_words)} ä¸ªæ ¸å¿ƒè¯æ±‡éƒ½å·²ä½¿ç”¨ï¼")
    
    # 5. æ£€æŸ¥é¢å¤–å•è¯ï¼ˆä¸åœ¨æ ¸å¿ƒåˆ—è¡¨ä¸­çš„ï¼‰
    extra_words = used_words - set([w.lower() for w in target_words])
    if extra_words:
        print(f"\nğŸ’¡ é¢å¤–ä½¿ç”¨çš„å•è¯ï¼ˆä¸åœ¨æ ¸å¿ƒåˆ—è¡¨ä¸­çš„ï¼‰ï¼š{len(extra_words)} ä¸ª")
        print(f"   {', '.join(list(extra_words)[:15])}")
        if len(extra_words) > 15:
            print(f"   ... è¿˜æœ‰ {len(extra_words) - 15} ä¸ª")
    
    # 6. å­—æ•°ç»Ÿè®¡
    char_count = len(story_content)
    word_count = len(story_content.replace(" ", "").replace("\n", ""))
    print(f"\nğŸ“ å­—æ•°ç»Ÿè®¡ï¼š")
    print(f"   å­—ç¬¦æ•°ï¼š{char_count}")
    print(f"   ä¼°ç®—å­—æ•°ï¼šçº¦ {word_count // 2} å­—ï¼ˆä¸­æ–‡ï¼‰")
    
    if word_count < 1400:
        print(f"   âš ï¸  å­—æ•°å¯èƒ½è¿‡å°‘ï¼ˆå»ºè®® 1400-1600 å­—ï¼‰")
    elif word_count > 2000:
        print(f"   âš ï¸  å­—æ•°å¯èƒ½è¿‡å¤šï¼ˆå»ºè®® 1400-1600 å­—ï¼‰")
    else:
        print(f"   âœ… å­—æ•°ç¬¦åˆè¦æ±‚")
    
    print(f"\n{'='*60}")


if __name__ == "__main__":
    main()
